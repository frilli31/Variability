% Use only LaTeX2e, calling the article.cls class and 12-point type.

\documentclass[12pt]{article}

% Users of the {thebibliography} environment or BibTeX should use the
% scicite.sty package, downloadable from *Science* at
% www.sciencemag.org/about/authors/prep/TeX_help/ .
% This package should properly format in-text
% reference calls and reference-list numbers.

\usepackage{scicite}

% Use times if you have the font installed; otherwise, comment out the
% following line.

%\usepackage{times}

% The preamble here sets up a lot of new/revised commands and
% environments.  It's annoying, but please do *not* try to strip these
% out into a separate .sty file (which could lead to the loss of some
% information when we convert the file to other formats).  Instead, keep
% them in the preamble of your main LaTeX source file.


% The following parameters seem to provide a reasonable page setup.

\topmargin 0.0cm
\oddsidemargin 0.2cm
\textwidth 16cm 
\textheight 21cm
\footskip 1.0cm


%The next command sets up an environment for the abstract to your paper.

\newenvironment{sciabstract}{%
\begin{quote} \bf}
{\end{quote}}


% If your reference list includes text notes as well as references,
% include the following line; otherwise, comment it out.

\renewcommand\refname{References and Notes}

% The following lines set up an environment for the last note in the
% reference list, which commonly includes acknowledgments of funding,
% help, etc.  It's intended for users of BibTeX or the {thebibliography}
% environment.  Users who are hand-coding their references at the end
% using a list environment such as {enumerate} can simply add another
% item at the end, and it will be numbered automatically.

\newcounter{lastnote}
\newenvironment{scilastnote}{%
\setcounter{lastnote}{\value{enumiv}}%
\addtocounter{lastnote}{+1}%
\begin{list}%
{\arabic{lastnote}.}
{\setlength{\leftmargin}{.22in}}
{\setlength{\labelsep}{.5em}}}
{\end{list}}


% Include your paper's title here

\title{
		\includegraphics[scale=0.20]{logo-unipd}~ 
		\\[2cm]
		Report of {\it Process Mining\/} Project
	} 


% Place the author information here.  Please hand-code the contact
% information and notecalls; do *not* use \footnote commands.  Let the
% author contact information appear immediately below the author names
% as shown.  We would also prefer that you don't change the type-size
% settings shown here.

\author
{Luca Allegro 1211142 \\ Alberto Bezzon 1211016\\
\\
Department of Science (Computer Science), University of Padua
}

% Include the date command, but leave its argument blank.

\date{}



%%%%%%%%%%%%%%%%% END OF PREAMBLE %%%%%%%%%%%%%%%%

% My packages
\usepackage{graphicx}
\usepackage[newfloat]{minted}
\usepackage{caption}
\usepackage{placeins}
\usepackage{float}

\graphicspath{ {./images/} } 
%\usemintedstyle[python]{monokai}
\newenvironment{code}{\captionsetup{type=listing}}{}
\SetupFloatingEnvironment{listing}{name=Code snippet}
%\sloppy
\begin{document} 

% Double-space the manuscript.

\baselineskip18pt

% Make the title.

\maketitle 



% Place your abstract within the special {sciabstract} environment.

\begin{sciabstract}
	The purpose of this report is to present the \textit{Project 1: How much variable is my event log?} carried out for the Process Mining course at University of Padua.
\end{sciabstract}



% In setting up this template for *Science* papers, we've used both
% the \section* command and the \paragraph* command for topical
% divisions.  Which you use will of course depend on the type of paper
% you're writing.  Review Articles tend to have displayed headings, for
% which \section* is more appropriate; Research Articles, when they have
% formal topical divisions at all, tend to signal them with bold text
% that runs into the paragraph, for which \paragraph* is the right
% choice.  Either way, use the asterisk (*) modifier, as shown, to
% suppress numbering.

\newpage
\section*{Introduction}

The aim of this report is to sum up the Process Mining project. In this project we aim at measuring how much variable are event logs, in terms of variety of behavior. Computing the variability of a log can indeed be rather useful, for instance, to decide for (a procedural or a declarative) model discovery, or to decide which prediction technique to apply. The are a lot of different ways to measure the variability of an event log, three of them are described in the following sections.

A possible way to measure the variability of an event log is counting the number of variants that it contains. A second possibility is to average the edit distance between each pair of traces in the event log. 

The report is organized as follows: in Sec. \ref{firstApproach}, \ref{secondApproach} and \ref{thirdApproach}, the three ways to compute variability of a log have been proposed. For each section there are two subsections that explain advantages and disadvantages of the metric described in the section.


\section*{First approach}\label{firstApproach}

%The first and easiest way to measure variability of an event log is counting the number of variants that it contains. Recall the definition of process variant, that is a sequence of process activities, the following fuctions does what we just described:
The first and easiest way to measure variability of an event log is counting the number of variants that it contains. We recall the definition of event, traces, process variant and process log: an event is an occurrence of an activity in a particular process instance, a trace is a sequence of events of the same such instance, a process variant is a sequence of process activities and a log is a multiset of such traces. The following function compute this metric:

\begin{code}
	\captionof{listing}{Function compute\_variant\_variability}
	\label{code:code1}
	\begin{minted}[
	frame=lines,
	framesep=2mm,
	baselinestretch=1.2,
	fontsize=\footnotesize,
	linenos
	]{python}
def compute_variant_variability(log: lg.EventLog) -> int:
"""Compute the number of variants present in the event log

Args:
log (lg.EventLog): The log to examine

Returns:
int: The number of variants present in the event log
"""
# For each case of the log we construct a tuple with the names of events.
# Then we collect all of them in a set to remove duplicates.
# Eventually we compute the length of the set.
return len(set(tuple(event["concept:name"] for event in case) for case in log))
	\end{minted}
\end{code}


\noindent This is the simplest and intuitive way to compute log variability. However, this metric does not consider the size of the log, i.e. big size log are penalized with respect to small size log. There is also a second reason that this way is unhelpful to our goal: it does not consider how variants differ to one another.

\paragraph*{Example:} If we have a process log L\textsubscript{1}=[\textless a,b,c\textgreater\textsuperscript{10}, \textless b,c,d \textgreater\textsuperscript{20}] the function returns 2 because in the log there are two different variants. If the log is L\textsubscript{2}=[\textless a,b\textgreater, \textless b,c\textgreater, \textless c,d\textgreater] the function returns 3; but L\textsubscript{1} is bigger than L\textsubscript{2}. This example shows how poorly informative this metric.


\section*{Second approach}

In order to obtain a more informative metric to compute log variability, the second approach that we developed consists in averaging edit distance between each pair of traces in the event log. For this purpose, we decided to use the Levenshtein distance. Levenshtein edit distance is the most well-known string edit distance metric and it is defined by the number of insertions, deletions and substitutions required to convert one string into another. The basic idea to compute average edit distance is, first compute the sum of edit distance of all possible combination of two pair of traces and then divide it by the number of possible combination that is \texttt{size\_of\_log * (size\_of\_log - 1)}.

\begin{code}
	\captionof{listing}{Function compute\_edit\_distance\_variability}
	\label{code:code2}
	\begin{minted}[
frame=lines,
framesep=2mm,
baselinestretch=1.2,
fontsize=\footnotesize,
linenos
]{python}
def compute_edit_distance_variability(log: lg.EventLog) -> float:
"""Compute the average edit distance (Levenshtein distance) between each
pairs of traces.

This function uses function `eval` of module 'editdistance' because it's
implemented in C++ and it is faster than the corresponding implementation
in python.

Args:
log (EventLog): The log to examine

Returns:
float: the average edit distance between each pairs of traces
"""
# Create a dictionary which contains variants as keys and its number of
# occurrences as values
variants_and_counts = Counter(
tuple(event["concept:name"] for event in case) for case in log
)
size_of_log = len(log)

# For each pair of distinct variants (obtained by 'combinations') we
# compute the edit distance and we multiply it for number of
# occurrences of the variants.
# In the end we sum all of them.
sum_of_distances = sum(
num_of_items_1 * num_of_items_2 * editdistance.eval(variant1, variant2)
for (variant1, num_of_items_1), (variant2, num_of_items_2)
in combinations(variants_and_counts.items(), 2)
)

# We multiply the sum of distances by 2 because to add the sum of distances
# of each inverted pairs of variants.
# In the end we divide it by the number of possible combination of pair
# of traces
return float(sum_of_distances * 2) / (size_of_log * (size_of_log - 1))
	\end{minted}
\end{code}

\noident Some important caveats are:
\begin{itemize}
	%\item we use variants rather than traces because we calculate the edit distance of two different traces multiplied by the number of repetition of a trace instead of calculate edit distance between two traces n times (in row 10 of the previous snippets of code(riferimento))
	\item we use variants instead of the traces because, instead of calculating edit distance between two traces \textit{n} times, we calculate the edit distance of two different traces multiplying by the number of repetitions of a trace (\texttt{line 26} of the snippet \ref{code:code2}).
	\item \texttt{combination} method of the python library \texttt{itertools} provide all the combinations of length two of different variants (\texttt{line 29} of the snippet \ref{code:code2}); the only case not covered by combinations is when two traces have the same variant but the edit distance is 0, so it does not affect the result (because the sum of all distances does not change summing 0).
	\item To optimize the calculation of edit distance, we use a C++ library with API for python because the above function has high complexity and with very big log (e.g. BPIchallenge2011.xes) it takes very long time\footnote{We know that computing edit distance between two traces has complexity O(\textit{nm}) where \textit{n} and \textit{m} are the lengths of the traces. The whole function has a complexity of O(\textit{l}\^{}2*\textit{nm}) where \textit{l} is the number of variants in the event log.}.
\end{itemize}

\subsection*{Advantages}

\noident The main advantage is that this metric solves the problems of the metric described in Sect. \ref{firstApproach}. In fact:
\begin{itemize}
	\item it takes into account the size of the log. Unlike the previous metric, this doesn't penalize big size logs.
	\item it considers how variants differ one another.
\end{itemize}

\subsection*{Disadvantages}

This method has also the following disadvantages:
\begin{itemize}
	\item it is very time-consuming for big size logs due to the fact that it has a high complexity.
	\item it does not consider the length of each trace, that's why logs with long traces are penalized).\label{ref1}
\end{itemize}  

\paragraph*{Example:} Consider two logs L\textsubscript{1}=[\textless a,b \textgreater, \textless c,d \textgreater] and L\textsubscript{2}=[\textless a,b,c,d,e \textgreater, \textless a,b,c,f,g \textgreater]. \texttt{compute\_edit\_distance\_variability} returns 2 for both logs but L\textsubscript{1} has a higher variability w.r.t. L\textsubscript{2} that has the first three events equal in both traces. 

%We have tried another edit distance metric, that is Damerau-Levenshtein edit distance. This distance is similar to Levenshtein edit distance with the addition of another possible operation (transposition of two adjacent characters) to convet a string into another. This metric performs better than Levenshtein distance only in the case where two traces differs only by order of events at distance one.

\section*{Third approach}

To address the weakness of the metrics based on edit distance, we developed a third way that consists in normalization of edit distance.  We normalise edit distance by the greatest possible distance between the traces to reflect that a distance of one operation on two very long strings should be considered less significant than on very short strings. In this way, we are able to compare the result with logs with a different average length.
\begin{code}
	\captionof{listing}{Function compute\_my\_variability}
	\label{code:code3}
	\begin{minted}[
frame=lines,
framesep=2mm,
baselinestretch=1.2,
fontsize=\footnotesize,
linenos
]{python}
def compute_my_variability(log: lg.EventLog) -> float:
"""Compute the average of normalized edit distances (Levenshtein distance)
between each pairs of traces.

This function uses function `eval` of module 'editdistance' because it's
implemented in C++ and it is faster than the corresponding implementation
in python.

Args:
	log (EventLog): The log to examine

Returns:
	float: a number between 0 and 1 included. The higher the number the
	more similar the traces are
		- 0 : if all traces has nothing in common
		- 1 : all traces belongs to the same variant (are equals)
"""
# Create a dictionary which contains variants as keys and its number of
# occurrences as values
variants_and_counts = Counter(
			tuple(event["concept:name"] for event in case) for case in log
			)
size_of_log = len(log)

# For each pair of distinct variants (obtained by 'combinations') we
# compute the average edit distance normalized (divided by longest trace)
# and we multiply it for number of occurrences of the variants.
# In the end we sum all of them.
sum_of_distances = sum(
	float(num_of_items_1 * num_of_items_2 * editdistance.eval(variant1, variant2))
	/ max(len(variant1), len(variant2))
	for (variant1, num_of_items_1), (variant2, num_of_items_2)
	in combinations(variants_and_counts.items(), 2)
)

# We multiply the sum of distances by 2 because to add the sum of distances
# of each inverted pairs of variants
# In the end we divide it by the number of possible combination of pair
# of traces
return 1 - (sum_of_distances * 2 / (size_of_log * (size_of_log - 1)))
	\end{minted}
\end{code}

\subsection*{Advantages}

This metric produces a result in the range [0, 1], that is immediately interpretable because it represent the fraction of how traces are equals. In fact, the higher the number is, the
more similar the traces are. When this number is 0, all traces of a log have nothing in common. When it is 1, all traces of a log have the same variant. In conclusion, this metric solve the problem \ref{ref1}.

\paragraph*{Example:} Consider once again the two log of the previous example (L\textsubscript{1}=[\textless a,b \textgreater, \textless c,d \textgreater] and L\textsubscript{2}=[\textless a,b,c,d,e \textgreater, \textless a,b,c,f,g \textgreater] reported for convinience). \texttt{compute\_my\_variability} function returns 0 for L\textsubscript{1} which traces are completely different and 0.6 for L\textsubscript{2} which traces are somehow similar.

\subsection*{Disadvantages}

The main disadvantage of this metric is the that it does not consider cycles in traces, i.e. traces with a repeated number of event are wrongly penalized. See the following example.

\paragraph*{Example:} This metric penalize the following traces A = ABCBCBCE and B = ABCE.

\section*{BPI Challenge 2011}

In this section, we report and discuss the results of the three different metrics realized. The following table summarize the results.
\renewcommand{\arraystretch}{1.5}\\
\begin{table}[H]
	\centering
		\begin{tabular}{ |c|c|  }
			\hline
			Functions & Results \\
			\hline
			\textit{compute\_variant\_variability} & 981 \\ \hline
			\textit{compute\_edit\_distance\_variability} & 195.88194492325937 \\ \hline
			\textit{compute\_my\_variability} & 0.14258102346211654 \\
			\hline
		\end{tabular}
	\caption{Table of overall results}
	\label{table:1}
\end{table}

As you can see in Table 1, the result obtained applying \texttt{compute\_variant\_variability} is 981. This number indicates that BPIChallenge2011 log has a lot of variants. We verified this data importing the log on Disco and w.r.t. size of log (1143), the only conclusion is that most of traces are different one another. Eventually, this metric is too simple too capture an interesting variability that involves how different are this variants.

\smallskip  

The second result obtained applying \texttt{compute\_edit\_distance\_variability} is \textit{195.88194492325937}. This number is more informative w.r.t the previous result and it tell us that there is a big average edit distance between pair of traces, hence, the log has an high variability. But you cannot understand how much traces have something in common.

\smallskip

The last result obtained by applying \texttt{compute\_my\_variability} is \textit{0.14258102346211654}. This number gives more information than the others, because it tells how much two traces, random picked, have in common. In this case, the result is 15\% which means that traces are disequal (hanno poco in comune) and we can conclude that the log has high variability.

\section*{Instructions}

\begin{enumerate}
	\item Extract \textit{Progetto.zip}
	\item Open a terminal inside the folder
	\item Install requirements using the following command: \texttt{pip install requirements.txt}
	\item Run the tests using: \texttt{pytest}
	\item In file \texttt{main.py} you can find an use example and you can run it: \texttt{python main.py}
\end{enumerate}

\bibliography{scibib}

\bibliographystyle{Science}



% Following is a new environment, {scilastnote}, that's defined in the
% preamble and that allows authors to add a reference at the end of the
% list that's not signaled in the text; such references are used in
% *Science* for acknowledgments of funding, help, etc.

\begin{scilastnote}
\end{scilastnote}




% For your review copy (i.e., the file you initially send in for
% evaluation), you can use the {figure} environment and the
% \includegraphics command to stream your figures into the text, placing
% all figures at the end.  For the final, revised manuscript for
% acceptance and production, however, PostScript or other graphics
% should not be streamed into your compliled file.  Instead, set
% captions as simple paragraphs (with a \noindent tag), setting them
% off from the rest of the text with a \clearpage as shown  below, and
% submit figures as separate files according to the Art Department's
% instructions.


\clearpage



\end{document}




















